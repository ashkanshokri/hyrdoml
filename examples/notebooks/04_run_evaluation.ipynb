{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temporal Out-of-Sample Validation Tutorial\n",
    "\n",
    "In this tutorial, we'll demonstrate how to perform temporal out-of-sample validation using the full CAMELS-Australia dataset instead of sample data. We'll leverage the built-in tools from the `hydroml` package to automatically handle data loading and execute the training and evaluation pipeline.\n",
    "\n",
    "The workflow will:\n",
    "1. Load the CAMELS-Australia dataset\n",
    "2. Set up temporal splits for calibration and validation\n",
    "3. Train and fine-tune a model\n",
    "4. Evaluate model performance\n",
    "\n",
    "Let's get started!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hydroml.config.config import Config\n",
    "from hydroml.workflow.evaluation import train_finetune_evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up the path mapping\n",
    "\n",
    "As this training is going to load the dataset automativally from camels australia, we need to set up the path mapping first. The method to set up the path mapping is the same as the one in the 03_build_a_path_mapping.ipynb tutorial.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We assume that the path mapping is already set up with the platform name 'win_2'.\n",
    "platform='win_2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need a list of basins for calibration and validation. These catchments should be already available in the camels australia postprocessed dataset and awara postprocessed dataset. So the pipeline will automatically load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "basins_file = '../sample_data/basins.txt'\n",
    "with open(basins_file, 'r') as f:\n",
    "    catchment_ids = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using these information we can set up the config object.\n",
    "\n",
    "For a full explanation of the config object please refer to the readme documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we only use 2 catchments for calibration and validation for this tutorial.\n",
    "config = Config(cal={'periods' : [['1991-01-01', '2014-01-01']], 'catchment_ids':catchment_ids[:2] },  \n",
    "                val={'periods' : [['1985-01-01', '1990-01-01']], 'catchment_ids':catchment_ids[:2] }, \n",
    "                name = 'evaluation_tutorial',\n",
    "                lstm_hidden_size=4, # we are selecting a small lstm size for this tutorial.\n",
    "                device='cpu',\n",
    "                platform=platform, # to introduce the paths stored in config/path_mapping/win.yaml\n",
    "                max_epochs=2, # and we reduce the number of epochs to 2 for this tutorial.\n",
    "                )    \n",
    "\n",
    "# we  need to call this function to set up the version name - or you can manually set it up.\n",
    "config.set_new_version_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now we can run the **training and evaluation pipeline**. This pipeline works as follows:\n",
    "\n",
    "1. Trains a **continental model** and evaluates it on the validation set.  \n",
    "2. Starts the **fine-tuning process**, where the continental model is fine-tuned for each catchment and then evaluated on that specific catchment.\n",
    "\n",
    "The results will be stored in the following structure:\n",
    "\n",
    "| **File/Folder**                          | **Description**                                                      | **Path**                                                          |\n",
    "|------------------------------------------|----------------------------------------------------------------------|-------------------------------------------------------------------|\n",
    "| **Model Weights**                        | Weights of the trained continental model.                           | `root_path/VERSION_NAME/last.ckpt`                                |\n",
    "| **Config File**                          | Configuration settings for the pipeline.                            | `root_path/VERSION_NAME/config.yaml`                              |\n",
    "| **Transformer Parameters**               | Parameters for the transformer model.                               | `root_path/VERSION_NAME/params.yaml`                              |\n",
    "| **Simulation Results (Continental Model)** | Simulation output for the continental model.                        | `root_path/VERSION_NAME/simulation.nc`                            |\n",
    "| **Metrics**                              | Evaluation metrics for the continental model.                       | `root_path/VERSION_NAME/metrics.nc`                               |\n",
    "| **Fine-tuned Models**                    | Fine-tuned models for each catchment.                               | `root_path/VERSION_NAME/finetune_all/catchment_id/VERSION_NAME/last.ckpt` |\n",
    "\n",
    "- Note 1: that the finetuned models are stored with a same structure as the continental model.\n",
    "- Note 2: the finetuned models do not have a params.yaml file as they are config to use the transformer parameter in the continental model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming data: calculating transform parameters and saving to \\\\fs1-cbr.nexus.csiro.au\\{d61-coastal-forecasting-wp3}\\work\\sho108_handover\\models\\evaluation_tutorial\\241217143238_a69e\\params.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sho108\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hydroml-dFLAodHf-py3.11\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:617: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 10 (`cpuset` is not taken into account), which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid data points per catchment {0: 5381, 1: 2219}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming data: loading transform parameters from \\\\fs1-cbr.nexus.csiro.au\\{d61-coastal-forecasting-wp3}\\work\\sho108_handover\\models\\evaluation_tutorial\\241217143238_a69e\\params.yaml\n",
      "\\\\fs1-cbr.nexus.csiro.au\\{d61-coastal-forecasting-wp3}\\work\\sho108_handover\\models\\evaluation_tutorial\\241217143238_a69e\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sho108\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hydroml-dFLAodHf-py3.11\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:617: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 10 (`cpuset` is not taken into account), which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\sho108\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hydroml-dFLAodHf-py3.11\\Lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:654: Checkpoint directory \\\\fs1-cbr.nexus.csiro.au\\{d61-coastal-forecasting-wp3}\\work\\sho108_handover\\models\\evaluation_tutorial\\241217143238_a69e exists and is not empty.\n",
      "\n",
      "  | Name              | Type       | Params | Mode \n",
      "---------------------------------------------------------\n",
      "0 | static_embedding  | Linear     | 15     | train\n",
      "1 | dynamic_embedding | Linear     | 5      | train\n",
      "2 | lstm              | LSTM       | 128    | train\n",
      "3 | dropout           | Identity   | 0      | train\n",
      "4 | head              | Sequential | 61     | train\n",
      "---------------------------------------------------------\n",
      "209       Trainable params\n",
      "0         Non-trainable params\n",
      "209       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c31e86eff624a21a82fb020c56e42d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sho108\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hydroml-dFLAodHf-py3.11\\Lib\\site-packages\\pytorch_lightning\\utilities\\data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 512. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "c:\\Users\\sho108\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hydroml-dFLAodHf-py3.11\\Lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2baa552ef6954174bf32786def3555b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sho108\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hydroml-dFLAodHf-py3.11\\Lib\\site-packages\\pytorch_lightning\\utilities\\data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 432. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "c:\\Users\\sho108\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hydroml-dFLAodHf-py3.11\\Lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:384: `ModelCheckpoint(monitor='val_loss')` could not find the monitored key in the returned metrics: ['lr-Adam', 'train_loss', 'epoch', 'step']. HINT: Did you call `log('val_loss', value)` in the `LightningModule`?\n",
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n",
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming data: loading transform parameters from \\\\fs1-cbr.nexus.csiro.au\\{d61-coastal-forecasting-wp3}\\work\\sho108_handover\\models\\evaluation_tutorial\\241217143238_a69e\\params.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sho108\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hydroml-dFLAodHf-py3.11\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:617: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 10 (`cpuset` is not taken into account), which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming data: loading transform parameters from \\\\fs1-cbr.nexus.csiro.au\\{d61-coastal-forecasting-wp3}\\work\\sho108_handover\\models\\evaluation_tutorial\\241217143238_a69e\\params.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sho108\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hydroml-dFLAodHf-py3.11\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:617: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 10 (`cpuset` is not taken into account), which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\sho108\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hydroml-dFLAodHf-py3.11\\Lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:654: Checkpoint directory \\\\fs1-cbr.nexus.csiro.au\\{d61-coastal-forecasting-wp3}\\work\\sho108_handover\\models\\evaluation_tutorial\\241217143238_a69e\\finetune_all\\912101A\\241217143420_1376 exists and is not empty.\n",
      "\n",
      "  | Name              | Type       | Params | Mode \n",
      "---------------------------------------------------------\n",
      "0 | static_embedding  | Linear     | 15     | train\n",
      "1 | dynamic_embedding | Linear     | 5      | train\n",
      "2 | lstm              | LSTM       | 128    | train\n",
      "3 | dropout           | Identity   | 0      | train\n",
      "4 | head              | Sequential | 61     | train\n",
      "---------------------------------------------------------\n",
      "209       Trainable params\n",
      "0         Non-trainable params\n",
      "209       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming data: loading transform parameters from \\\\fs1-cbr.nexus.csiro.au\\{d61-coastal-forecasting-wp3}\\work\\sho108_handover\\models\\evaluation_tutorial\\241217143238_a69e\\params.yaml\n",
      "\\\\fs1-cbr.nexus.csiro.au\\{d61-coastal-forecasting-wp3}\\work\\sho108_handover\\models\\evaluation_tutorial\\241217143238_a69e\\finetune_all\\912101A\\241217143420_1376\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "723753f8ba774a7b8dc1796bea1f8114",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sho108\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hydroml-dFLAodHf-py3.11\\Lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:298: The number of training batches (11) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af63582959b84dec82fdeca5daddabb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sho108\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hydroml-dFLAodHf-py3.11\\Lib\\site-packages\\pytorch_lightning\\utilities\\data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 261. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70df18d92d2c4628abb67f76f6b1ce6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sho108\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hydroml-dFLAodHf-py3.11\\Lib\\site-packages\\pytorch_lightning\\utilities\\data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 72. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8908279dc3c4d8bba66c5f6dc824f0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "032f4de8b9064e5db24175fa074c288a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=15` reached.\n",
      "c:\\Users\\sho108\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hydroml-dFLAodHf-py3.11\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:617: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 10 (`cpuset` is not taken into account), which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming data: loading transform parameters from \\\\fs1-cbr.nexus.csiro.au\\{d61-coastal-forecasting-wp3}\\work\\sho108_handover\\models\\evaluation_tutorial\\241217143238_a69e\\params.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming data: loading transform parameters from \\\\fs1-cbr.nexus.csiro.au\\{d61-coastal-forecasting-wp3}\\work\\sho108_handover\\models\\evaluation_tutorial\\241217143238_a69e\\params.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sho108\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hydroml-dFLAodHf-py3.11\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:617: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 10 (`cpuset` is not taken into account), which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\sho108\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hydroml-dFLAodHf-py3.11\\Lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:654: Checkpoint directory \\\\fs1-cbr.nexus.csiro.au\\{d61-coastal-forecasting-wp3}\\work\\sho108_handover\\models\\evaluation_tutorial\\241217143238_a69e\\finetune_all\\912105A\\241217143613_4c35 exists and is not empty.\n",
      "\n",
      "  | Name              | Type       | Params | Mode \n",
      "---------------------------------------------------------\n",
      "0 | static_embedding  | Linear     | 15     | train\n",
      "1 | dynamic_embedding | Linear     | 5      | train\n",
      "2 | lstm              | LSTM       | 128    | train\n",
      "3 | dropout           | Identity   | 0      | train\n",
      "4 | head              | Sequential | 61     | train\n",
      "---------------------------------------------------------\n",
      "209       Trainable params\n",
      "0         Non-trainable params\n",
      "209       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming data: loading transform parameters from \\\\fs1-cbr.nexus.csiro.au\\{d61-coastal-forecasting-wp3}\\work\\sho108_handover\\models\\evaluation_tutorial\\241217143238_a69e\\params.yaml\n",
      "\\\\fs1-cbr.nexus.csiro.au\\{d61-coastal-forecasting-wp3}\\work\\sho108_handover\\models\\evaluation_tutorial\\241217143238_a69e\\finetune_all\\912105A\\241217143613_4c35\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "945bb27299cd43f6a723baa5b243ca7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sho108\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hydroml-dFLAodHf-py3.11\\Lib\\site-packages\\pytorch_lightning\\utilities\\data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 296. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "c:\\Users\\sho108\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hydroml-dFLAodHf-py3.11\\Lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:298: The number of training batches (5) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e34c010b9d5a4dcf94adc26cfeb00df9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sho108\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hydroml-dFLAodHf-py3.11\\Lib\\site-packages\\pytorch_lightning\\utilities\\data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 171. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7d5f939141d44a48586c0a331011f08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "793583daeb304a0986bb0d3d67ef244a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48dd3e94f1a9438bb7bde37abb8afaab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=15` reached.\n",
      "c:\\Users\\sho108\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hydroml-dFLAodHf-py3.11\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:617: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 10 (`cpuset` is not taken into account), which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming data: loading transform parameters from \\\\fs1-cbr.nexus.csiro.au\\{d61-coastal-forecasting-wp3}\\work\\sho108_handover\\models\\evaluation_tutorial\\241217143238_a69e\\params.yaml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WindowsPath('//fs1-cbr.nexus.csiro.au/{d61-coastal-forecasting-wp3}/work/sho108_handover/models/evaluation_tutorial/241217143238_a69e')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_finetune_evaluate(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the new set of results for the simulation over the validtion period using the continental model is stored in the following path:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
       "<defs>\n",
       "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
       "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "</symbol>\n",
       "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
       "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "</symbol>\n",
       "</defs>\n",
       "</svg>\n",
       "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
       " *\n",
       " */\n",
       "\n",
       ":root {\n",
       "  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n",
       "  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));\n",
       "  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));\n",
       "  --xr-border-color: var(--jp-border-color2, #e0e0e0);\n",
       "  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);\n",
       "  --xr-background-color: var(--jp-layout-color0, white);\n",
       "  --xr-background-color-row-even: var(--jp-layout-color1, white);\n",
       "  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n",
       "}\n",
       "\n",
       "html[theme=\"dark\"],\n",
       "html[data-theme=\"dark\"],\n",
       "body[data-theme=\"dark\"],\n",
       "body.vscode-dark {\n",
       "  --xr-font-color0: rgba(255, 255, 255, 1);\n",
       "  --xr-font-color2: rgba(255, 255, 255, 0.54);\n",
       "  --xr-font-color3: rgba(255, 255, 255, 0.38);\n",
       "  --xr-border-color: #1f1f1f;\n",
       "  --xr-disabled-color: #515151;\n",
       "  --xr-background-color: #111111;\n",
       "  --xr-background-color-row-even: #111111;\n",
       "  --xr-background-color-row-odd: #313131;\n",
       "}\n",
       "\n",
       ".xr-wrap {\n",
       "  display: block !important;\n",
       "  min-width: 300px;\n",
       "  max-width: 700px;\n",
       "}\n",
       "\n",
       ".xr-text-repr-fallback {\n",
       "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-header {\n",
       "  padding-top: 6px;\n",
       "  padding-bottom: 6px;\n",
       "  margin-bottom: 4px;\n",
       "  border-bottom: solid 1px var(--xr-border-color);\n",
       "}\n",
       "\n",
       ".xr-header > div,\n",
       ".xr-header > ul {\n",
       "  display: inline;\n",
       "  margin-top: 0;\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-obj-type,\n",
       ".xr-array-name {\n",
       "  margin-left: 2px;\n",
       "  margin-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-obj-type {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-sections {\n",
       "  padding-left: 0 !important;\n",
       "  display: grid;\n",
       "  grid-template-columns: 150px auto auto 1fr 0 20px 0 20px;\n",
       "}\n",
       "\n",
       ".xr-section-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-section-item input {\n",
       "  display: inline-block;\n",
       "  opacity: 0;\n",
       "  height: 0;\n",
       "}\n",
       "\n",
       ".xr-section-item input + label {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label {\n",
       "  cursor: pointer;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-item input:focus + label {\n",
       "  border: 2px solid var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label:hover {\n",
       "  color: var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-summary {\n",
       "  grid-column: 1;\n",
       "  color: var(--xr-font-color2);\n",
       "  font-weight: 500;\n",
       "}\n",
       "\n",
       ".xr-section-summary > span {\n",
       "  display: inline-block;\n",
       "  padding-left: 0.5em;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in + label:before {\n",
       "  display: inline-block;\n",
       "  content: \"►\";\n",
       "  font-size: 11px;\n",
       "  width: 15px;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label:before {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label:before {\n",
       "  content: \"▼\";\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label > span {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-summary,\n",
       ".xr-section-inline-details {\n",
       "  padding-top: 4px;\n",
       "  padding-bottom: 4px;\n",
       "}\n",
       "\n",
       ".xr-section-inline-details {\n",
       "  grid-column: 2 / -1;\n",
       "}\n",
       "\n",
       ".xr-section-details {\n",
       "  display: none;\n",
       "  grid-column: 1 / -1;\n",
       "  margin-bottom: 5px;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked ~ .xr-section-details {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-array-wrap {\n",
       "  grid-column: 1 / -1;\n",
       "  display: grid;\n",
       "  grid-template-columns: 20px auto;\n",
       "}\n",
       "\n",
       ".xr-array-wrap > label {\n",
       "  grid-column: 1;\n",
       "  vertical-align: top;\n",
       "}\n",
       "\n",
       ".xr-preview {\n",
       "  color: var(--xr-font-color3);\n",
       "}\n",
       "\n",
       ".xr-array-preview,\n",
       ".xr-array-data {\n",
       "  padding: 0 5px !important;\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-array-data,\n",
       ".xr-array-in:checked ~ .xr-array-preview {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-array-in:checked ~ .xr-array-data,\n",
       ".xr-array-preview {\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".xr-dim-list {\n",
       "  display: inline-block !important;\n",
       "  list-style: none;\n",
       "  padding: 0 !important;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list li {\n",
       "  display: inline-block;\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list:before {\n",
       "  content: \"(\";\n",
       "}\n",
       "\n",
       ".xr-dim-list:after {\n",
       "  content: \")\";\n",
       "}\n",
       "\n",
       ".xr-dim-list li:not(:last-child):after {\n",
       "  content: \",\";\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-has-index {\n",
       "  font-weight: bold;\n",
       "}\n",
       "\n",
       ".xr-var-list,\n",
       ".xr-var-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-var-item > div,\n",
       ".xr-var-item label,\n",
       ".xr-var-item > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-even);\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-var-item > .xr-var-name:hover span {\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-var-list > li:nth-child(odd) > div,\n",
       ".xr-var-list > li:nth-child(odd) > label,\n",
       ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-odd);\n",
       "}\n",
       "\n",
       ".xr-var-name {\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-var-dims {\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-var-dtype {\n",
       "  grid-column: 3;\n",
       "  text-align: right;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-preview {\n",
       "  grid-column: 4;\n",
       "}\n",
       "\n",
       ".xr-index-preview {\n",
       "  grid-column: 2 / 5;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-name,\n",
       ".xr-var-dims,\n",
       ".xr-var-dtype,\n",
       ".xr-preview,\n",
       ".xr-attrs dt {\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-var-name:hover,\n",
       ".xr-var-dims:hover,\n",
       ".xr-var-dtype:hover,\n",
       ".xr-attrs dt:hover {\n",
       "  overflow: visible;\n",
       "  width: auto;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  display: none;\n",
       "  background-color: var(--xr-background-color) !important;\n",
       "  padding-bottom: 5px !important;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
       ".xr-var-data-in:checked ~ .xr-var-data,\n",
       ".xr-index-data-in:checked ~ .xr-index-data {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".xr-var-data > table {\n",
       "  float: right;\n",
       "}\n",
       "\n",
       ".xr-var-name span,\n",
       ".xr-var-data,\n",
       ".xr-index-name div,\n",
       ".xr-index-data,\n",
       ".xr-attrs {\n",
       "  padding-left: 25px !important;\n",
       "}\n",
       "\n",
       ".xr-attrs,\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  grid-column: 1 / -1;\n",
       "}\n",
       "\n",
       "dl.xr-attrs {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  display: grid;\n",
       "  grid-template-columns: 125px auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt,\n",
       ".xr-attrs dd {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  float: left;\n",
       "  padding-right: 10px;\n",
       "  width: auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt {\n",
       "  font-weight: normal;\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-attrs dt:hover span {\n",
       "  display: inline-block;\n",
       "  background: var(--xr-background-color);\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-attrs dd {\n",
       "  grid-column: 2;\n",
       "  white-space: pre-wrap;\n",
       "  word-break: break-all;\n",
       "}\n",
       "\n",
       ".xr-icon-database,\n",
       ".xr-icon-file-text2,\n",
       ".xr-no-icon {\n",
       "  display: inline-block;\n",
       "  vertical-align: middle;\n",
       "  width: 1em;\n",
       "  height: 1.5em !important;\n",
       "  stroke-width: 0;\n",
       "  stroke: currentColor;\n",
       "  fill: currentColor;\n",
       "}\n",
       "</style><pre class='xr-text-repr-fallback'>&lt;xarray.Dataset&gt; Size: 35kB\n",
       "Dimensions:       (date: 1462, catchment_id: 2, lead_time: 1, feature: 1)\n",
       "Coordinates:\n",
       "  * date          (date) datetime64[ns] 12kB 1986-01-01 ... 1990-01-01\n",
       "  * catchment_id  (catchment_id) &lt;U7 56B &#x27;912101A&#x27; &#x27;912105A&#x27;\n",
       "Dimensions without coordinates: lead_time, feature\n",
       "Data variables:\n",
       "    prediction    (lead_time, feature, date, catchment_id) float32 12kB ...\n",
       "    y             (lead_time, feature, date, catchment_id) float32 12kB ...</pre><div class='xr-wrap' style='display:none'><div class='xr-header'><div class='xr-obj-type'>xarray.Dataset</div></div><ul class='xr-sections'><li class='xr-section-item'><input id='section-30db6d2e-f61d-4377-9f4e-058115b40822' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-30db6d2e-f61d-4377-9f4e-058115b40822' class='xr-section-summary'  title='Expand/collapse section'>Dimensions:</label><div class='xr-section-inline-details'><ul class='xr-dim-list'><li><span class='xr-has-index'>date</span>: 1462</li><li><span class='xr-has-index'>catchment_id</span>: 2</li><li><span>lead_time</span>: 1</li><li><span>feature</span>: 1</li></ul></div><div class='xr-section-details'></div></li><li class='xr-section-item'><input id='section-8be548a0-7e1a-4340-b998-e7576872c2d8' class='xr-section-summary-in' type='checkbox'  checked><label for='section-8be548a0-7e1a-4340-b998-e7576872c2d8' class='xr-section-summary' >Coordinates: <span>(2)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>date</span></div><div class='xr-var-dims'>(date)</div><div class='xr-var-dtype'>datetime64[ns]</div><div class='xr-var-preview xr-preview'>1986-01-01 ... 1990-01-01</div><input id='attrs-43c710d0-ed95-4a46-aab1-aff2d9f23492' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-43c710d0-ed95-4a46-aab1-aff2d9f23492' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-495f2cd0-e354-4d6e-9f05-19e23f6d9c41' class='xr-var-data-in' type='checkbox'><label for='data-495f2cd0-e354-4d6e-9f05-19e23f6d9c41' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([&#x27;1986-01-01T00:00:00.000000000&#x27;, &#x27;1986-01-02T00:00:00.000000000&#x27;,\n",
       "       &#x27;1986-01-03T00:00:00.000000000&#x27;, ..., &#x27;1989-12-30T00:00:00.000000000&#x27;,\n",
       "       &#x27;1989-12-31T00:00:00.000000000&#x27;, &#x27;1990-01-01T00:00:00.000000000&#x27;],\n",
       "      dtype=&#x27;datetime64[ns]&#x27;)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>catchment_id</span></div><div class='xr-var-dims'>(catchment_id)</div><div class='xr-var-dtype'>&lt;U7</div><div class='xr-var-preview xr-preview'>&#x27;912101A&#x27; &#x27;912105A&#x27;</div><input id='attrs-e9ae05c4-9c4a-40dd-874f-59aa27879e0d' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-e9ae05c4-9c4a-40dd-874f-59aa27879e0d' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-6ee227c9-99ab-4e55-ae97-3369eff5483e' class='xr-var-data-in' type='checkbox'><label for='data-6ee227c9-99ab-4e55-ae97-3369eff5483e' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([&#x27;912101A&#x27;, &#x27;912105A&#x27;], dtype=&#x27;&lt;U7&#x27;)</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-d69cc7c3-dc6b-4e86-9713-dc69010d36f6' class='xr-section-summary-in' type='checkbox'  checked><label for='section-d69cc7c3-dc6b-4e86-9713-dc69010d36f6' class='xr-section-summary' >Data variables: <span>(2)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span>prediction</span></div><div class='xr-var-dims'>(lead_time, feature, date, catchment_id)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-68191ea2-d592-407b-b241-27a04d3c10f9' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-68191ea2-d592-407b-b241-27a04d3c10f9' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-0293e19e-4f62-4885-b685-d1bb0ab7a6bf' class='xr-var-data-in' type='checkbox'><label for='data-0293e19e-4f62-4885-b685-d1bb0ab7a6bf' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>[2924 values with dtype=float32]</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>y</span></div><div class='xr-var-dims'>(lead_time, feature, date, catchment_id)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-31d58eac-2137-4e18-853a-263e9581963a' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-31d58eac-2137-4e18-853a-263e9581963a' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-3eb5897b-0e8b-4b3f-a07c-50d7e0d7177d' class='xr-var-data-in' type='checkbox'><label for='data-3eb5897b-0e8b-4b3f-a07c-50d7e0d7177d' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>[2924 values with dtype=float32]</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-abe41608-611e-45b0-838b-9ce760f7b922' class='xr-section-summary-in' type='checkbox'  ><label for='section-abe41608-611e-45b0-838b-9ce760f7b922' class='xr-section-summary' >Indexes: <span>(2)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-index-name'><div>date</div></div><div class='xr-index-preview'>PandasIndex</div><input type='checkbox' disabled/><label></label><input id='index-7797f610-9a4b-4d14-982c-9b76639718e1' class='xr-index-data-in' type='checkbox'/><label for='index-7797f610-9a4b-4d14-982c-9b76639718e1' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(DatetimeIndex([&#x27;1986-01-01&#x27;, &#x27;1986-01-02&#x27;, &#x27;1986-01-03&#x27;, &#x27;1986-01-04&#x27;,\n",
       "               &#x27;1986-01-05&#x27;, &#x27;1986-01-06&#x27;, &#x27;1986-01-07&#x27;, &#x27;1986-01-08&#x27;,\n",
       "               &#x27;1986-01-09&#x27;, &#x27;1986-01-10&#x27;,\n",
       "               ...\n",
       "               &#x27;1989-12-23&#x27;, &#x27;1989-12-24&#x27;, &#x27;1989-12-25&#x27;, &#x27;1989-12-26&#x27;,\n",
       "               &#x27;1989-12-27&#x27;, &#x27;1989-12-28&#x27;, &#x27;1989-12-29&#x27;, &#x27;1989-12-30&#x27;,\n",
       "               &#x27;1989-12-31&#x27;, &#x27;1990-01-01&#x27;],\n",
       "              dtype=&#x27;datetime64[ns]&#x27;, name=&#x27;date&#x27;, length=1462, freq=None))</pre></div></li><li class='xr-var-item'><div class='xr-index-name'><div>catchment_id</div></div><div class='xr-index-preview'>PandasIndex</div><input type='checkbox' disabled/><label></label><input id='index-56f9739c-284e-4823-b1fc-d5a00b7f73fb' class='xr-index-data-in' type='checkbox'/><label for='index-56f9739c-284e-4823-b1fc-d5a00b7f73fb' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Index([&#x27;912101A&#x27;, &#x27;912105A&#x27;], dtype=&#x27;object&#x27;, name=&#x27;catchment_id&#x27;))</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-296c4d78-57c3-4d37-ac5d-0de72eb33994' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-296c4d78-57c3-4d37-ac5d-0de72eb33994' class='xr-section-summary'  title='Expand/collapse section'>Attributes: <span>(0)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'></dl></div></li></ul></div></div>"
      ],
      "text/plain": [
       "<xarray.Dataset> Size: 35kB\n",
       "Dimensions:       (date: 1462, catchment_id: 2, lead_time: 1, feature: 1)\n",
       "Coordinates:\n",
       "  * date          (date) datetime64[ns] 12kB 1986-01-01 ... 1990-01-01\n",
       "  * catchment_id  (catchment_id) <U7 56B '912101A' '912105A'\n",
       "Dimensions without coordinates: lead_time, feature\n",
       "Data variables:\n",
       "    prediction    (lead_time, feature, date, catchment_id) float32 12kB ...\n",
       "    y             (lead_time, feature, date, catchment_id) float32 12kB ..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xarray as xr\n",
    "\n",
    "p = config.current_path / config.version /'results' / 'simulation.nc'\n",
    "xr.open_dataset(p)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hydroml-dFLAodHf-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
