{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from hydroml.training.train import train\n",
    "from hydroml.config.config import Config, load_config\n",
    "import hydroml.training.finetune as ft\n",
    "from hydroml.models import get_model_from_path\n",
    "from hydroml.data.camels_aus_ds import get_dataset\n",
    "from hydroml.prediction.prediction import process_and_convert_dataloader_to_xarray\n",
    "from hydroml.models.get_model_from_path import get_model_from_path\n",
    "from hydroml.evaluation.metrics import get_metrics\n",
    "from hydroml.training.trainer import get_trainer\n",
    "from pathlib import Path\n",
    "def plot(ds):\n",
    "    ds.prediction.plot()\n",
    "    ds.y.plot()\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.legend(['prediction', 'y'])\n",
    "    plt.ylim(0, 5)\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('P://work//sho108//hydroml//workflows//basins.txt', 'r') as f:\n",
    "    basins = f.read().splitlines()\n",
    "\n",
    "catchment_ids = basins#'410730'\n",
    "# '410730'\n",
    "config = Config(cal={'periods' : [['1985-01-01', '2014-01-01']], 'catchment_ids':catchment_ids}, #, 'weights': [1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
    "                val={'periods' : [['1985-01-01', '2014-01-01']], 'catchment_ids':catchment_ids[0:1]}, #,\n",
    "                max_epochs=15,\n",
    "                lstm_hidden_size=256,\n",
    "                batch_size=256,\n",
    "                initial_forget_bias=0,\n",
    "                parent_path = 'P://work//sho108//hydroml//results_2',\n",
    "                lr=1e-3,\n",
    "                dataloader_nworkers=9,\n",
    "                dataloader_persistent_workers=True                \n",
    "                )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming data: loading transform parameters from P:\\work\\sho108\\hydroml\\results_2\\default\\params.yaml\n",
      "valid data points per catchment {0: 9853, 1: 7590, 2: 8049, 3: 9642, 4: 8473, 5: 7756, 6: 6931, 7: 8093, 8: 8417, 9: 9326, 10: 9841, 11: 8445, 12: 9364, 13: 10145, 14: 10533, 15: 8518, 16: 10473, 17: 10194, 18: 9946, 19: 10311, 20: 10124, 21: 10533, 22: 10473, 23: 10533, 24: 10473, 25: 10473, 26: 10533, 27: 10342, 28: 10437, 29: 10419, 30: 9383, 31: 10220, 32: 10432, 33: 10533, 34: 10296, 35: 10379, 36: 10339, 37: 9907, 38: 10109, 39: 10467, 40: 10466, 41: 10467, 42: 10264, 43: 10439, 44: 10533, 45: 10007, 46: 10533, 47: 10533, 48: 10533, 49: 10462, 50: 10467, 51: 10446, 52: 9784, 53: 10462, 54: 10533, 55: 10473, 56: 10466, 57: 10451, 58: 10309, 59: 10533, 60: 10284, 61: 10272, 62: 10533, 63: 9610, 64: 9407, 65: 10438, 66: 10409, 67: 10011, 68: 10533, 69: 10441, 70: 10066, 71: 10341, 72: 10302, 73: 10095, 74: 8769, 75: 10174, 76: 10470, 77: 10289, 78: 10450, 79: 10303, 80: 10264, 81: 10403, 82: 10403, 83: 10457, 84: 8860, 85: 9311, 86: 9450, 87: 7989, 88: 9888, 89: 9245, 90: 9185, 91: 10533, 92: 8538, 93: 8083, 94: 7286, 95: 8281, 96: 7514, 97: 7805, 98: 8154, 99: 8905, 100: 9784, 101: 9187, 102: 9800, 103: 9260, 104: 9007, 105: 9278, 106: 10533, 107: 9750, 108: 9039, 109: 8639, 110: 8555, 111: 8935, 112: 8992, 113: 8736, 114: 8947, 115: 6373, 116: 7465, 117: 9988, 118: 9220, 119: 9127, 120: 9084, 121: 6527, 122: 8614, 123: 9690, 124: 8239, 125: 10070, 126: 9539, 127: 8959, 128: 9050, 129: 9298, 130: 9463, 131: 9693, 132: 9241, 133: 9772, 134: 9751, 135: 10533, 136: 6586, 137: 9754, 138: 9972, 139: 10382, 140: 10463, 141: 10096, 142: 10439, 143: 10033, 144: 9808, 145: 9930, 146: 9992, 147: 8880, 148: 8167, 149: 9479, 150: 9415, 151: 9778, 152: 9825, 153: 9566, 154: 9437, 155: 10533, 156: 10533, 157: 10533, 158: 10533, 159: 10469, 160: 10212, 161: 10533, 162: 10533, 163: 10462, 164: 10409, 165: 7926, 166: 9274, 167: 10447, 168: 9426, 169: 8628, 170: 7532, 171: 10447, 172: 10533, 173: 10533, 174: 7559, 175: 8019, 176: 10411, 177: 10133, 178: 10533, 179: 10446, 180: 10471, 181: 10214, 182: 10437, 183: 10419, 184: 10533, 185: 10533, 186: 10533, 187: 6400, 188: 7499, 189: 10533, 190: 8442, 191: 10533, 192: 10533, 193: 10533, 194: 10533, 195: 10533, 196: 7175, 197: 5125, 198: 10391, 199: 9694, 200: 9797, 201: 8801, 202: 9461, 203: 9774, 204: 8802, 205: 9229, 206: 9205, 207: 8865, 208: 8058, 209: 6657, 210: 8368, 211: 10372, 212: 9599, 213: 10471, 214: 10350, 215: 9360, 216: 10221, 217: 10205, 218: 9777, 219: 9817, 220: 10197, 221: 9994}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False                                       \n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming data: loading transform parameters from P:\\work\\sho108\\hydroml\\results_2\\default\\params.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sho108\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hydroml-dFLAodHf-py3.11\\Lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:654: Checkpoint directory \\\\fs1-cbr.nexus.csiro.au\\{ev-ca-macq}\\work\\sho108\\hydroml\\results_2\\default\\241210215144_6580 exists and is not empty.\n",
      "\n",
      "  | Name              | Type       | Params | Mode \n",
      "---------------------------------------------------------\n",
      "0 | static_embedding  | Linear     | 15     | train\n",
      "1 | dynamic_embedding | Linear     | 5      | train\n",
      "2 | lstm              | LSTM       | 266 K  | train\n",
      "3 | dropout           | Identity   | 0      | train\n",
      "4 | head              | Sequential | 2.6 K  | train\n",
      "---------------------------------------------------------\n",
      "268 K     Trainable params\n",
      "0         Non-trainable params\n",
      "268 K     Total params\n",
      "1.075     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79c4b444502d49cfad653673bde176b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sho108\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hydroml-dFLAodHf-py3.11\\Lib\\site-packages\\pytorch_lightning\\utilities\\data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 256. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ffc65c7f4b643b5a481323b1cfa3aa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sho108\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hydroml-dFLAodHf-py3.11\\Lib\\site-packages\\pytorch_lightning\\utilities\\data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 102. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "c:\\Users\\sho108\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hydroml-dFLAodHf-py3.11\\Lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:384: `ModelCheckpoint(monitor='val_loss')` could not find the monitored key in the returned metrics: ['lr-Adam', 'train_loss', 'epoch', 'step']. HINT: Did you call `log('val_loss', value)` in the `LightningModule`?\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7a3e397ff134b7b9302364c79ac0174",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sho108\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hydroml-dFLAodHf-py3.11\\Lib\\site-packages\\pytorch_lightning\\utilities\\data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 125. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "current_path_pre, version_pre = train(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first pass:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming data: loading transform parameters from P:\\work\\sho108\\hydroml\\results_2\\default\\params.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sho108\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hydroml-dFLAodHf-py3.11\\Lib\\site-packages\\xarray\\core\\computation.py:818: RuntimeWarning: invalid value encountered in sqrt\n",
      "  result_data = func(*input_data)\n",
      "c:\\Users\\sho108\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hydroml-dFLAodHf-py3.11\\Lib\\site-packages\\xarray\\core\\computation.py:818: RuntimeWarning: invalid value encountered in sqrt\n",
      "  result_data = func(*input_data)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>nse</th>\n",
       "      <th>kge</th>\n",
       "      <th>rmse</th>\n",
       "      <th>bias</th>\n",
       "      <th>relative_bias</th>\n",
       "      <th>absolute_bias</th>\n",
       "      <th>nse_sqrt</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>catchment_id</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>feature</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>102101A</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <td>0.131709</td>\n",
       "      <td>-0.202987</td>\n",
       "      <td>7.970991</td>\n",
       "      <td>0.220550</td>\n",
       "      <td>-0.779450</td>\n",
       "      <td>0.220550</td>\n",
       "      <td>-0.082133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104001A</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <td>0.322257</td>\n",
       "      <td>-0.342095</td>\n",
       "      <td>3.557014</td>\n",
       "      <td>-0.161673</td>\n",
       "      <td>-1.161674</td>\n",
       "      <td>0.161673</td>\n",
       "      <td>-0.557289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105101A</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <td>0.054011</td>\n",
       "      <td>-0.521051</td>\n",
       "      <td>2.872990</td>\n",
       "      <td>-0.168064</td>\n",
       "      <td>-1.168064</td>\n",
       "      <td>0.168064</td>\n",
       "      <td>-1.928226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105102A</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <td>0.093461</td>\n",
       "      <td>-0.532059</td>\n",
       "      <td>3.326761</td>\n",
       "      <td>-0.179544</td>\n",
       "      <td>-1.179544</td>\n",
       "      <td>0.179544</td>\n",
       "      <td>-1.266895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105105A</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <td>0.564584</td>\n",
       "      <td>0.155063</td>\n",
       "      <td>3.049018</td>\n",
       "      <td>0.283162</td>\n",
       "      <td>-0.716838</td>\n",
       "      <td>0.283162</td>\n",
       "      <td>-0.022017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G8200045</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <td>0.068976</td>\n",
       "      <td>-0.454449</td>\n",
       "      <td>4.115690</td>\n",
       "      <td>-0.140012</td>\n",
       "      <td>-1.140012</td>\n",
       "      <td>0.140012</td>\n",
       "      <td>-1.626599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G8210010</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <td>0.003885</td>\n",
       "      <td>-0.497147</td>\n",
       "      <td>4.975430</td>\n",
       "      <td>-0.122652</td>\n",
       "      <td>-1.122652</td>\n",
       "      <td>0.122652</td>\n",
       "      <td>-2.880549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G9030124</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <td>-0.326678</td>\n",
       "      <td>-3.372349</td>\n",
       "      <td>1.189864</td>\n",
       "      <td>-3.342604</td>\n",
       "      <td>-4.342604</td>\n",
       "      <td>3.342604</td>\n",
       "      <td>-4.154618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G9030250</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <td>-0.253677</td>\n",
       "      <td>-1.239589</td>\n",
       "      <td>0.721052</td>\n",
       "      <td>2.736631</td>\n",
       "      <td>1.736631</td>\n",
       "      <td>2.736631</td>\n",
       "      <td>-1.109347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G9070142</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <td>-0.001610</td>\n",
       "      <td>-1.555587</td>\n",
       "      <td>1.310386</td>\n",
       "      <td>-1.364802</td>\n",
       "      <td>-2.364802</td>\n",
       "      <td>1.364802</td>\n",
       "      <td>-4.330011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>222 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     nse       kge      rmse      bias  \\\n",
       "catchment_id lead_time feature                                           \n",
       "102101A      0         0        0.131709 -0.202987  7.970991  0.220550   \n",
       "104001A      0         0        0.322257 -0.342095  3.557014 -0.161673   \n",
       "105101A      0         0        0.054011 -0.521051  2.872990 -0.168064   \n",
       "105102A      0         0        0.093461 -0.532059  3.326761 -0.179544   \n",
       "105105A      0         0        0.564584  0.155063  3.049018  0.283162   \n",
       "...                                  ...       ...       ...       ...   \n",
       "G8200045     0         0        0.068976 -0.454449  4.115690 -0.140012   \n",
       "G8210010     0         0        0.003885 -0.497147  4.975430 -0.122652   \n",
       "G9030124     0         0       -0.326678 -3.372349  1.189864 -3.342604   \n",
       "G9030250     0         0       -0.253677 -1.239589  0.721052  2.736631   \n",
       "G9070142     0         0       -0.001610 -1.555587  1.310386 -1.364802   \n",
       "\n",
       "                                relative_bias  absolute_bias  nse_sqrt  \n",
       "catchment_id lead_time feature                                          \n",
       "102101A      0         0            -0.779450       0.220550 -0.082133  \n",
       "104001A      0         0            -1.161674       0.161673 -0.557289  \n",
       "105101A      0         0            -1.168064       0.168064 -1.928226  \n",
       "105102A      0         0            -1.179544       0.179544 -1.266895  \n",
       "105105A      0         0            -0.716838       0.283162 -0.022017  \n",
       "...                                       ...            ...       ...  \n",
       "G8200045     0         0            -1.140012       0.140012 -1.626599  \n",
       "G8210010     0         0            -1.122652       0.122652 -2.880549  \n",
       "G9030124     0         0            -4.342604       3.342604 -4.154618  \n",
       "G9030250     0         0             1.736631       2.736631 -1.109347  \n",
       "G9070142     0         0            -2.364802       1.364802 -4.330011  \n",
       "\n",
       "[222 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print('first pass:')\n",
    "dataset_cal_train = get_dataset(config, 'cal', is_train=True)\n",
    "dataloader_cal_train = dataset_cal_train.to_dataloader()\n",
    "pretrained_model_path = Path('P://work//sho108//hydroml//results_2//default//241210215144_6580')\n",
    "model = get_model_from_path(pretrained_model_path)\n",
    "ds_pre = process_and_convert_dataloader_to_xarray(dataloader_cal_train, model, config)\n",
    "m_pre = get_metrics(ds_pre)\n",
    "m_pre.to_dataframe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataArray' object has no attribute 'sort_values'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mm_pre\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnse\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort_values\u001b[49m(ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\sho108\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\hydroml-dFLAodHf-py3.11\\Lib\\site-packages\\xarray\\core\\common.py:302\u001b[0m, in \u001b[0;36mAttrAccessMixin.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    300\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m suppress(\u001b[38;5;167;01mKeyError\u001b[39;00m):\n\u001b[0;32m    301\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m source[name]\n\u001b[1;32m--> 302\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m    303\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    304\u001b[0m )\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataArray' object has no attribute 'sort_values'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "pretrained_model_path = current_path_pre/version_pre #Path('P://work//sho108//hydroml//results_2//default//241210160237_1337')\n",
    "for i, catchment_id in enumerate(catchment_ids):\n",
    "    print(f'{i+1}/{len(catchment_ids)}: {catchment_id}')\n",
    "\n",
    "    print(f'second pass using finetuning module: {catchment_id}')\n",
    "    if catchment_id in results:\n",
    "        continue\n",
    "    #reload_model\n",
    "    model = get_model_from_path(pretrained_model_path, check_point='last')\n",
    "    config = ft.update_config_for_per_catchment_finetune(config, cal_catchment_ids=[catchment_id], val_catchment_ids=[catchment_id], max_epochs=5)\n",
    "    \n",
    "    current_path, version = ft.finetune(model, config, finetune_directory='finetune', finetune_name=catchment_id)\n",
    "\n",
    "    ft_model = get_model_from_path(current_path/version, check_point='last')\n",
    "\n",
    "    ds = process_and_convert_dataloader_to_xarray(dataloader_cal_train, ft_model, config)\n",
    "    m = get_metrics(ds)\n",
    "    \n",
    "    results[catchment_id] = m.to_dataframe()\n",
    "\n",
    "    print('-'*100)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "results_list = []\n",
    "for k in results:\n",
    "    results_list.append(results[k].loc[[k]])\n",
    "\n",
    "fine_tuned_results  = pd.concat(results_list)\n",
    "\n",
    "\n",
    "total_results = pd.concat([m_pre.to_dataframe()['nse'], fine_tuned_results['nse']], axis=1)\n",
    "total_results.columns = ['pretrained', 'fine_tuned']\n",
    "\n",
    "total_results.dropna(inplace=True)\n",
    "\n",
    "sorted_pretrained = total_results['pretrained'].sort_values(ascending=False).values\n",
    "sorted_fine_tuned = total_results['fine_tuned'].sort_values(ascending=False).values\n",
    "\n",
    "\n",
    "# plot exceedance curve\n",
    "import matplotlib.pyplot as plt\n",
    "x = np.linspace(0,1,len(sorted_pretrained))\n",
    "plt.plot(x, sorted_pretrained)\n",
    "plt.plot(x, sorted_fine_tuned)\n",
    "plt.legend(['pretrained', 'fine_tuned'])\n",
    "\n",
    "plt.ylim(0,1)\n",
    "plt.show()\n",
    "\n",
    "diff = total_results['fine_tuned'] - total_results['pretrained']\n",
    "sorted_diff = diff.sort_values(ascending=False).values\n",
    "np.clip(sorted_diff, -1, 1, out=sorted_diff)\n",
    "\n",
    "# count how many catchments have positive improvement\n",
    "print(f'{((sorted_diff > 0).sum() / len(sorted_diff))*100:.2f}% of catchments have positive improvement')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hydroml-dFLAodHf-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
